{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7882668,"sourceType":"datasetVersion","datasetId":4626740}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt # for plotting\nimport numpy as np # for transformation\n\nimport torch # PyTorch package\nimport torchvision # load datasets\nimport torchvision.transforms as transforms # transform data\nimport torch.nn as nn # basic building block for neural neteorks\nimport torch.nn.functional as F # import convolution functions like Relu\nimport torch.optim as optim # optimzer\nfrom torch.utils.data import DataLoader, ConcatDataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T00:46:45.247900Z","iopub.execute_input":"2024-03-20T00:46:45.248311Z","iopub.status.idle":"2024-03-20T00:46:48.357843Z","shell.execute_reply.started":"2024-03-20T00:46:45.248280Z","shell.execute_reply":"2024-03-20T00:46:48.356763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available()) ","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:46:50.011261Z","iopub.execute_input":"2024-03-20T00:46:50.012152Z","iopub.status.idle":"2024-03-20T00:46:50.047581Z","shell.execute_reply.started":"2024-03-20T00:46:50.012113Z","shell.execute_reply":"2024-03-20T00:46:50.045878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets\n\ntransform = transforms.Compose([\n    transforms.Resize((140, 140)), #Resizing all images since they have different sizes\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(15),\n    transforms.RandomPerspective(),\n    transforms.ColorJitter(),\n    transforms.ToTensor(), # to tensor object\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n\n# set batch_size\nbatch_size = 4\n\nnum_workers = 4","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:46:57.667492Z","iopub.execute_input":"2024-03-20T00:46:57.667874Z","iopub.status.idle":"2024-03-20T00:46:57.676946Z","shell.execute_reply.started":"2024-03-20T00:46:57.667845Z","shell.execute_reply":"2024-03-20T00:46:57.675829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validationset =torchvision.datasets.ImageFolder(root='/kaggle/input/cs-131-edited-dataset/split_ttv_dataset_type_of_plants/Validation_Set_Folder', transform=transform)\ntrainset = torchvision.datasets.ImageFolder(root='/kaggle/input/cs-131-edited-dataset/split_ttv_dataset_type_of_plants/Train_Set_Folder', transform=transform)\n\n# Combining training and validation to make a bigger training set\ncombined_dataset = ConcatDataset([validationset, trainset])\ntrainloader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n\ntestset = torchvision.datasets.ImageFolder(root='/kaggle/input/cs-131-edited-dataset/split_ttv_dataset_type_of_plants/Test_Set_Folder', transform=transform)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n\nclasses = ('aloevera', 'banana', 'bilimbi',\n           'cassava', 'coconut', 'corn', 'cucumber', 'curcuma', 'eggplant', 'ginger', 'guava', 'kale', 'longbeans', 'mango', 'melon', 'orange', 'paddy', 'papaya', 'peper chili', 'pineapple', 'pomelo', 'shallot', 'soybeans', 'spinach', 'sweet potatoes', 'tobacco', 'waterapple', 'watermelon')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n  ''' function to show image '''\n  img = img / 2 + 0.5 # unnormalize\n  npimg = img.numpy() # convert to numpy objects\n  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n  plt.show()\n\n# get random training images with iter function\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# call function on our images\nimshow(torchvision.utils.make_grid(images))\n\n# print the class of the image\nprint(' '.join('%s' % classes[labels[j]] for j in range(batch_size)))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:47:07.731895Z","iopub.execute_input":"2024-03-20T00:47:07.732292Z","iopub.status.idle":"2024-03-20T00:47:08.399085Z","shell.execute_reply.started":"2024-03-20T00:47:07.732264Z","shell.execute_reply":"2024-03-20T00:47:08.397868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    ''' Models a simple Convolutional Neural Network'''\n\n    def __init__(self):\n        ''' initialize the network '''\n        super(Net, self).__init__()\n        # 3 input image channel, 16 output channels, \n        # 5x5 square convolution kernel\n        self.conv1 = nn.Conv2d(3, 16, 5)\n        # Max pooling over a (2, 2) window\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bnorm1 = nn.BatchNorm2d(16)\n        self.conv2 = nn.Conv2d(16, 32, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bnorm2 = nn.BatchNorm2d(32)\n        self.conv3 = nn.Conv2d(32, 64, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bnorm2 = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 128, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bnorm4 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(128 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 28)\n\n    def forward(self, x):\n        ''' the forward propagation algorithm '''\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        x = self.pool(F.relu(self.conv4(x)))\n        x = x.view(-1, 128 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:47:28.607984Z","iopub.execute_input":"2024-03-20T00:47:28.608977Z","iopub.status.idle":"2024-03-20T00:47:28.638301Z","shell.execute_reply.started":"2024-03-20T00:47:28.608933Z","shell.execute_reply":"2024-03-20T00:47:28.636898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:47:33.732336Z","iopub.execute_input":"2024-03-20T00:47:33.733197Z","iopub.status.idle":"2024-03-20T00:47:33.739846Z","shell.execute_reply.started":"2024-03-20T00:47:33.733167Z","shell.execute_reply":"2024-03-20T00:47:33.738739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = torch.cuda.Event(enable_timing=True)\nend = torch.cuda.Event(enable_timing=True)\n\nstart.record()\n\nfor epoch in range(50):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n    \n    \n    scheduler.step()\n\n# whatever you are timing goes here\nend.record()\n\n# Waits for everything to finish running\ntorch.cuda.synchronize()\n\nprint('Finished Training')\nprint(start.elapsed_time(end))  # milliseconds","metadata":{"execution":{"iopub.status.busy":"2024-03-20T00:47:38.676823Z","iopub.execute_input":"2024-03-20T00:47:38.677181Z","iopub.status.idle":"2024-03-20T05:18:27.292275Z","shell.execute_reply.started":"2024-03-20T00:47:38.677155Z","shell.execute_reply":"2024-03-20T05:18:27.291008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join('%s' % classes[labels[j]] for j in range(4)))\n\noutputs = net(images)\n\n_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join('%s' % classes[predicted[j]]\n                              for j in range(4)))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:20:13.063842Z","iopub.execute_input":"2024-03-20T05:20:13.064800Z","iopub.status.idle":"2024-03-20T05:20:13.607606Z","shell.execute_reply.started":"2024-03-20T05:20:13.064759Z","shell.execute_reply":"2024-03-20T05:20:13.605812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images (unseen data): %d %%' % (\n    100 * correct / total))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\ntotal = 0\nwith torch.no_grad():\n    for data in trainloader:\n        images, labels = data\n        outputs = net(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the training images (seen data): %d %%' % (\n    100 * correct / total))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T05:21:14.368523Z","iopub.execute_input":"2024-03-20T05:21:14.369356Z","iopub.status.idle":"2024-03-20T05:23:58.357799Z","shell.execute_reply.started":"2024-03-20T05:21:14.369318Z","shell.execute_reply":"2024-03-20T05:23:58.356594Z"},"trusted":true},"execution_count":null,"outputs":[]}]}